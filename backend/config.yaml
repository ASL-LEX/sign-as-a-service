pretrained: "sign_recognizer.ckpt"
data:
    modality: "pose"

    test_pipeline:
        results: ./predictions.jsonl
        dataset:
            _target_: openhands.datasets.isolated.WLASLDataset
            split_file: ./vocab_new.json
            root_dir: ./poses/
            modality: "pose"
            inference_mode: true
        
        transforms:
            - PoseSelect:
                preset: mediapipe_holistic_minimal_27
            - CenterAndScaleNormalize:
                reference_points_preset: shoulder_mediapipe_holistic_minimal_27
                scale_factor: 1

        dataloader:
            _target_: torch.utils.data.DataLoader
            batch_size: 1
            shuffle: false
            num_workers: 0
            pin_memory: true
            drop_last: false

        parameters: ["gloss"]
        
model:
    learn_adapter: false
    adapter_source: []
    encoder:
        type: decoupled-gcn
        params:
            graph_args:
                num_nodes: 27
                inward_edges:
                    [
                        [2, 0],
                        [1, 0],
                        [0, 3],
                        [0, 4],
                        [3, 5],
                        [4, 6],
                        [5, 7],
                        [6, 17],
                        [7, 8],
                        [7, 9],
                        [9, 10],
                        [7, 11],
                        [11, 12],
                        [7, 13],
                        [13, 14],
                        [7, 15],
                        [15, 16],
                        [17, 18],
                        [17, 19],
                        [19, 20],
                        [17, 21],
                        [21, 22],
                        [17, 23],
                        [23, 24],
                        [17, 25],
                        [25, 26],
                    ]
    decoder:
        type: param_fc
        params:
            dropout_ratio: 0

optim:
    loss: 'CrossEntropyLoss'
    optimizer:
        name: Adam
        params:
            lr: 1e-3

    scheduler:
        name: CosineAnnealingLR
        params:
            last_epoch: -1
            T_max: 10

trainer:
    gpus: 0
    max_epochs: 100
    resume_from_checkpoint: false #./pretrained_models/mjr_sample.ckpt

exp_manager:
    create_tensorboard_logger: true
    create_wandb_logger: false
    wandb_logger_kwargs:
        name: multitask_16_semassoc
        project: openhands

    create_checkpoint_callback: true
    checkpoint_callback_params:
        monitor: "val_acc"
        mode: "max"
        save_top_k: 1
        dirpath: "./pretrained_models/multitask/"

    early_stopping_callback: true
    early_stopping_params:
        monitor: "val_acc"
        patience: 80
        verbose: true
        mode: "max"
